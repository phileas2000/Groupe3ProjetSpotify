{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Predict whether a mammogram mass is benign or malignant\n",
    "\n",
    "We'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass)\n",
    "\n",
    "This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n",
    "\n",
    "\n",
    "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "   2. Age: patient's age in years (integer)\n",
    "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "   6. Severity: benign=0 or malignant=1 (binominal)\n",
    "   \n",
    "BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n",
    "\n",
    "Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n",
    "\n",
    "A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. If we can build a better way to interpret them through supervised machine learning, it could improve a lot of lives.\n",
    "\n",
    "## Your assignment\n",
    "\n",
    "Build a Multi-Layer Perceptron and train it to classify masses as benign or malignant based on its features.\n",
    "\n",
    "The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n",
    "\n",
    "Remember to normalize your data first! And experiment with different topologies, optimizers, and hyperparameters.\n",
    "\n",
    "I was able to achieve over 80% accuracy - can you beat that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's begin: prepare your data\n",
    "\n",
    "Start by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "conn = sql.connect('../spotify.db')\n",
    "#chansons_data = pd.read_csv(r'C:\\Users\\Simplon 1\\Documents\\Projets\\Spotify\\Spotify(1)\\chansons.csv' ,encoding=\"UTF8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chansons_data['top50']=0\n",
    "chansons_data.at[0:50,'top50']=1\n",
    "chansons_data.head(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>id_artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>top50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>93802</td>\n",
       "      <td>4iJyoBOLtHqaGxP12qzhQI</td>\n",
       "      <td>Peaches (feat. Daniel Caesar &amp; Giveon)</td>\n",
       "      <td>100</td>\n",
       "      <td>198082</td>\n",
       "      <td>1</td>\n",
       "      <td>['Justin Bieber', 'Daniel Caesar', 'Giveon']</td>\n",
       "      <td>['1uNFoZAHBGtllmzznpCI3s', '20wkVLutqVOYrc0kxF...</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.464</td>\n",
       "      <td>90.030</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>93803</td>\n",
       "      <td>7lPN2DXiMsVn7XUKtOW1CS</td>\n",
       "      <td>drivers license</td>\n",
       "      <td>99</td>\n",
       "      <td>242014</td>\n",
       "      <td>1</td>\n",
       "      <td>['Olivia Rodrigo']</td>\n",
       "      <td>['1McMsnEElThX1knmY4oliG']</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.132</td>\n",
       "      <td>143.874</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>93804</td>\n",
       "      <td>3Ofmpyhv5UAQ70mENzB277</td>\n",
       "      <td>Astronaut In The Ocean</td>\n",
       "      <td>98</td>\n",
       "      <td>132780</td>\n",
       "      <td>0</td>\n",
       "      <td>['Masked Wolf']</td>\n",
       "      <td>['1uU7g3DNSbsu0QjSEqZtEd']</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.865</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.472</td>\n",
       "      <td>149.996</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92811</td>\n",
       "      <td>6tDDoYIxWvMLTdKpjFkc1B</td>\n",
       "      <td>telepatía</td>\n",
       "      <td>97</td>\n",
       "      <td>160191</td>\n",
       "      <td>0</td>\n",
       "      <td>['Kali Uchis']</td>\n",
       "      <td>['1U1el3k54VvEUzo3ybLPlM']</td>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.553</td>\n",
       "      <td>83.970</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>92810</td>\n",
       "      <td>5QO79kh1waicV47BqGRL3g</td>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>97</td>\n",
       "      <td>215627</td>\n",
       "      <td>1</td>\n",
       "      <td>['The Weeknd']</td>\n",
       "      <td>['1Xyo4u8uXC1ZmMpatF05PJ']</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.644</td>\n",
       "      <td>118.051</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                      id  \\\n",
       "0        0  93802  4iJyoBOLtHqaGxP12qzhQI   \n",
       "1        1  93803  7lPN2DXiMsVn7XUKtOW1CS   \n",
       "2        2  93804  3Ofmpyhv5UAQ70mENzB277   \n",
       "3        3  92811  6tDDoYIxWvMLTdKpjFkc1B   \n",
       "4        4  92810  5QO79kh1waicV47BqGRL3g   \n",
       "\n",
       "                                     name  popularity  duration_ms  explicit  \\\n",
       "0  Peaches (feat. Daniel Caesar & Giveon)         100       198082         1   \n",
       "1                         drivers license          99       242014         1   \n",
       "2                  Astronaut In The Ocean          98       132780         0   \n",
       "3                               telepatía          97       160191         0   \n",
       "4                         Save Your Tears          97       215627         1   \n",
       "\n",
       "                                        artists  \\\n",
       "0  ['Justin Bieber', 'Daniel Caesar', 'Giveon']   \n",
       "1                            ['Olivia Rodrigo']   \n",
       "2                               ['Masked Wolf']   \n",
       "3                                ['Kali Uchis']   \n",
       "4                                ['The Weeknd']   \n",
       "\n",
       "                                          id_artists release_date  ...  \\\n",
       "0  ['1uNFoZAHBGtllmzznpCI3s', '20wkVLutqVOYrc0kxF...   2021-03-19  ...   \n",
       "1                         ['1McMsnEElThX1knmY4oliG']   2021-01-08  ...   \n",
       "2                         ['1uU7g3DNSbsu0QjSEqZtEd']   2021-01-06  ...   \n",
       "3                         ['1U1el3k54VvEUzo3ybLPlM']   2020-12-04  ...   \n",
       "4                         ['1Xyo4u8uXC1ZmMpatF05PJ']   2020-03-20  ...   \n",
       "\n",
       "   loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0    -6.181     1       0.1190        0.3210          0.000000     0.420   \n",
       "1    -8.761     1       0.0601        0.7210          0.000013     0.105   \n",
       "2    -6.865     0       0.0913        0.1750          0.000000     0.150   \n",
       "3    -9.016     0       0.0502        0.1120          0.000000     0.203   \n",
       "4    -5.487     1       0.0309        0.0212          0.000012     0.543   \n",
       "\n",
       "   valence    tempo  time_signature  top50  \n",
       "0    0.464   90.030               4      1  \n",
       "1    0.132  143.874               4      1  \n",
       "2    0.472  149.996               4      1  \n",
       "3    0.553   83.970               4      1  \n",
       "4    0.644  118.051               4      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chansons_data = pd.read_csv(r'C:\\Users\\Simplon 1\\Documents\\Projets\\Spotify\\Spotify(1)\\chansons.csv',encoding=\"UTF8\", na_values=['?'])\n",
    "chansons_data = pd.read_sql_query(\"select * from Chansons ORDER BY popularity  DESC\",conn)\n",
    "top50_data = pd.read_sql_query(\"select * from best_chansons \",conn)\n",
    "chansons_data['top50']=0\n",
    "top50_data['top50']=1\n",
    "chansons_data = pd.concat([top50_data,chansons_data])\n",
    "\n",
    "chansons_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>top50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1.050000e+03</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>285259.327619</td>\n",
       "      <td>289552.775238</td>\n",
       "      <td>29.986667</td>\n",
       "      <td>2.296842e+05</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.567690</td>\n",
       "      <td>0.539367</td>\n",
       "      <td>5.153333</td>\n",
       "      <td>-10.120407</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.099262</td>\n",
       "      <td>0.455269</td>\n",
       "      <td>0.115828</td>\n",
       "      <td>0.212344</td>\n",
       "      <td>0.543312</td>\n",
       "      <td>116.380131</td>\n",
       "      <td>3.874286</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>174664.831496</td>\n",
       "      <td>171084.723019</td>\n",
       "      <td>22.410117</td>\n",
       "      <td>1.031453e+05</td>\n",
       "      <td>0.211024</td>\n",
       "      <td>0.165592</td>\n",
       "      <td>0.246434</td>\n",
       "      <td>3.515770</td>\n",
       "      <td>4.903837</td>\n",
       "      <td>0.485852</td>\n",
       "      <td>0.171339</td>\n",
       "      <td>0.348864</td>\n",
       "      <td>0.270526</td>\n",
       "      <td>0.172839</td>\n",
       "      <td>0.257313</td>\n",
       "      <td>29.084873</td>\n",
       "      <td>0.459417</td>\n",
       "      <td>0.213060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.381300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.253000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>46.282000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>131867.500000</td>\n",
       "      <td>128401.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.750568e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.353250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-12.841500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.115250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.338250</td>\n",
       "      <td>94.177750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>288254.500000</td>\n",
       "      <td>286842.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>2.164780e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-9.342500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043050</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>114.252500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>434337.750000</td>\n",
       "      <td>439225.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.644630e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687750</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-6.541750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072175</td>\n",
       "      <td>0.792250</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>134.216000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>586231.000000</td>\n",
       "      <td>585212.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.305307e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.826000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>206.119000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             level_0          index   popularity   duration_ms     explicit  \\\n",
       "count    1050.000000    1050.000000  1050.000000  1.050000e+03  1050.000000   \n",
       "mean   285259.327619  289552.775238    29.986667  2.296842e+05     0.046667   \n",
       "std    174664.831496  171084.723019    22.410117  1.031453e+05     0.211024   \n",
       "min         0.000000     154.000000     0.000000  3.381300e+04     0.000000   \n",
       "25%    131867.500000  128401.500000    13.000000  1.750568e+05     0.000000   \n",
       "50%    288254.500000  286842.500000    27.500000  2.164780e+05     0.000000   \n",
       "75%    434337.750000  439225.500000    42.000000  2.644630e+05     0.000000   \n",
       "max    586231.000000  585212.000000   100.000000  1.305307e+06     1.000000   \n",
       "\n",
       "       danceability       energy          key     loudness         mode  \\\n",
       "count   1050.000000  1050.000000  1050.000000  1050.000000  1050.000000   \n",
       "mean       0.567690     0.539367     5.153333   -10.120407     0.619048   \n",
       "std        0.165592     0.246434     3.515770     4.903837     0.485852   \n",
       "min        0.066100     0.006510     0.000000   -32.253000     0.000000   \n",
       "25%        0.461000     0.353250     2.000000   -12.841500     0.000000   \n",
       "50%        0.578500     0.549000     5.000000    -9.342500     1.000000   \n",
       "75%        0.687750     0.732000     8.000000    -6.541750     1.000000   \n",
       "max        0.957000     0.997000    11.000000    -0.826000     1.000000   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness     liveness      valence  \\\n",
       "count  1050.000000   1050.000000       1050.000000  1050.000000  1050.000000   \n",
       "mean      0.099262      0.455269          0.115828     0.212344     0.543312   \n",
       "std       0.171339      0.348864          0.270526     0.172839     0.257313   \n",
       "min       0.022500      0.000001          0.000000     0.021500     0.030800   \n",
       "25%       0.033900      0.115250          0.000000     0.099200     0.338250   \n",
       "50%       0.043050      0.431000          0.000020     0.141000     0.553500   \n",
       "75%       0.072175      0.792250          0.010725     0.280000     0.749000   \n",
       "max       0.959000      0.996000          0.992000     0.985000     0.995000   \n",
       "\n",
       "             tempo  time_signature        top50  \n",
       "count  1050.000000     1050.000000  1050.000000  \n",
       "mean    116.380131        3.874286     0.047619  \n",
       "std      29.084873        0.459417     0.213060  \n",
       "min      46.282000        1.000000     0.000000  \n",
       "25%      94.177750        4.000000     0.000000  \n",
       "50%     114.252500        4.000000     0.000000  \n",
       "75%     134.216000        4.000000     0.000000  \n",
       "max     206.119000        5.000000     1.000000  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chansons_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chansons_data =chansons_data.sort_values('duration_ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''chansons_data.loc[(masses_data['popularity'].isnull()) |\n",
    "              (masses_data['duration_ms'].isnull()) |\n",
    "              (masses_data['explicit'].isnull()) |\n",
    "              (masses_data['danceability'].isnull()) |\n",
    "              (masses_data['energy'].isnull()) |\n",
    "              (masses_data['key'].isnull()) |\n",
    "              (masses_data['loudness'].isnull()) |\n",
    "              (masses_data['artists'].isnull())]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>top50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1.050000e+03</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>285259.327619</td>\n",
       "      <td>289552.775238</td>\n",
       "      <td>29.986667</td>\n",
       "      <td>2.296842e+05</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.567690</td>\n",
       "      <td>0.539367</td>\n",
       "      <td>5.153333</td>\n",
       "      <td>-10.120407</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.099262</td>\n",
       "      <td>0.455269</td>\n",
       "      <td>0.115828</td>\n",
       "      <td>0.212344</td>\n",
       "      <td>0.543312</td>\n",
       "      <td>116.380131</td>\n",
       "      <td>3.874286</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>174664.831496</td>\n",
       "      <td>171084.723019</td>\n",
       "      <td>22.410117</td>\n",
       "      <td>1.031453e+05</td>\n",
       "      <td>0.211024</td>\n",
       "      <td>0.165592</td>\n",
       "      <td>0.246434</td>\n",
       "      <td>3.515770</td>\n",
       "      <td>4.903837</td>\n",
       "      <td>0.485852</td>\n",
       "      <td>0.171339</td>\n",
       "      <td>0.348864</td>\n",
       "      <td>0.270526</td>\n",
       "      <td>0.172839</td>\n",
       "      <td>0.257313</td>\n",
       "      <td>29.084873</td>\n",
       "      <td>0.459417</td>\n",
       "      <td>0.213060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.381300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-32.253000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>46.282000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>131867.500000</td>\n",
       "      <td>128401.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.750568e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.353250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-12.841500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.115250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.338250</td>\n",
       "      <td>94.177750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>288254.500000</td>\n",
       "      <td>286842.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>2.164780e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-9.342500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043050</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>114.252500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>434337.750000</td>\n",
       "      <td>439225.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.644630e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687750</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-6.541750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072175</td>\n",
       "      <td>0.792250</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>134.216000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>586231.000000</td>\n",
       "      <td>585212.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.305307e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.826000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>206.119000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             level_0          index   popularity   duration_ms     explicit  \\\n",
       "count    1050.000000    1050.000000  1050.000000  1.050000e+03  1050.000000   \n",
       "mean   285259.327619  289552.775238    29.986667  2.296842e+05     0.046667   \n",
       "std    174664.831496  171084.723019    22.410117  1.031453e+05     0.211024   \n",
       "min         0.000000     154.000000     0.000000  3.381300e+04     0.000000   \n",
       "25%    131867.500000  128401.500000    13.000000  1.750568e+05     0.000000   \n",
       "50%    288254.500000  286842.500000    27.500000  2.164780e+05     0.000000   \n",
       "75%    434337.750000  439225.500000    42.000000  2.644630e+05     0.000000   \n",
       "max    586231.000000  585212.000000   100.000000  1.305307e+06     1.000000   \n",
       "\n",
       "       danceability       energy          key     loudness         mode  \\\n",
       "count   1050.000000  1050.000000  1050.000000  1050.000000  1050.000000   \n",
       "mean       0.567690     0.539367     5.153333   -10.120407     0.619048   \n",
       "std        0.165592     0.246434     3.515770     4.903837     0.485852   \n",
       "min        0.066100     0.006510     0.000000   -32.253000     0.000000   \n",
       "25%        0.461000     0.353250     2.000000   -12.841500     0.000000   \n",
       "50%        0.578500     0.549000     5.000000    -9.342500     1.000000   \n",
       "75%        0.687750     0.732000     8.000000    -6.541750     1.000000   \n",
       "max        0.957000     0.997000    11.000000    -0.826000     1.000000   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness     liveness      valence  \\\n",
       "count  1050.000000   1050.000000       1050.000000  1050.000000  1050.000000   \n",
       "mean      0.099262      0.455269          0.115828     0.212344     0.543312   \n",
       "std       0.171339      0.348864          0.270526     0.172839     0.257313   \n",
       "min       0.022500      0.000001          0.000000     0.021500     0.030800   \n",
       "25%       0.033900      0.115250          0.000000     0.099200     0.338250   \n",
       "50%       0.043050      0.431000          0.000020     0.141000     0.553500   \n",
       "75%       0.072175      0.792250          0.010725     0.280000     0.749000   \n",
       "max       0.959000      0.996000          0.992000     0.985000     0.995000   \n",
       "\n",
       "             tempo  time_signature        top50  \n",
       "count  1050.000000     1050.000000  1050.000000  \n",
       "mean    116.380131        3.874286     0.047619  \n",
       "std      29.084873        0.459417     0.213060  \n",
       "min      46.282000        1.000000     0.000000  \n",
       "25%      94.177750        4.000000     0.000000  \n",
       "50%     114.252500        4.000000     0.000000  \n",
       "75%     134.216000        4.000000     0.000000  \n",
       "max     206.119000        5.000000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chansons_data.dropna(inplace=True)\n",
    "chansons_data.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_features = masses_data[['explicit','speechiness','loudness','valence','duration_ms','danceability','energy']].values\n",
    "all_features = chansons_data[['popularity']].values\n",
    "\n",
    "all_classes = chansons_data[['top50']].values\n",
    "\n",
    "#feature_names = ['age', 'shape', 'margin', 'density']\n",
    "\n",
    "#all_features\n",
    "\n",
    "\n",
    "#données= pd.DataFrame(data,columns=['Age','Shape','Margin','Density'])\n",
    "#catégorie= pd.DataFrame(data,columns=['Severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     level_0   index                      id  \\\n",
      "670   403564  484601  3dylMkIuNcV5qQW2s5vOT5   \n",
      "947   552504   15104  0VPIRWFCiuAYx1NEGz1Vwl   \n",
      "969   563560  116346  0xB7vTtNikRDNrWozR6ETB   \n",
      "606   366165  577622  0etHcrwnc1vPsqvLrWJe7C   \n",
      "946   580440  451583  4MdMxmyUMyv4NrxcDFPab1   \n",
      "..       ...     ...                     ...   \n",
      "845   495459  505677  44pcaKv3RGu5PRQK9hagoA   \n",
      "987   550621   12238  6gfXtfyuTLU3C2fM4P00iu   \n",
      "921   540332  493119  1coKh01XUmxwQCCylLMU3Y   \n",
      "872   506916  219279  27lnVpIKy1eCAtKiGKoBId   \n",
      "949   557972   23261  0Rq2Q4RrAG0f7CiaV9KBDs   \n",
      "\n",
      "                                                  name  popularity  \\\n",
      "670                  De Globi planget uf de Geburtstag          17   \n",
      "947      24 Préludes, Op. 28: Prélude No. 5 in D Major           0   \n",
      "969  Verdi : La forza del destino : Act 2 \"La cena ...           0   \n",
      "606                           Tintin i Amerika, del 36          21   \n",
      "946  St. Matthew Passion, BWV 244 - Part Two: No.55...           0   \n",
      "..                                                 ...         ...   \n",
      "845                                    The Last Battle           6   \n",
      "987  Sonate pour piano No. 30 in E Major, Op. 109: ...           0   \n",
      "921  Beethoven: Symphony No. 3 in E-Flat Major, Op....           1   \n",
      "872                         Kamel El Awsaf Live Record           4   \n",
      "949            In the South Overture, Op. 50 \"Alassio\"           0   \n",
      "\n",
      "     duration_ms  explicit                                            artists  \\\n",
      "670        33813         0                                          ['Globi']   \n",
      "947        36667         0               ['Frédéric Chopin', 'Claudio Arrau']   \n",
      "969        36933         0  ['Giuseppe Verdi', 'Gino Marinuzzi', 'Bruno Er...   \n",
      "606        40733         0         ['Tintin', 'Tomas Bolme', 'Bert-Åke Varg']   \n",
      "946        42000         0  ['Johann Sebastian Bach', 'Karl Erb', 'Concert...   \n",
      "..           ...       ...                                                ...   \n",
      "845       729160         0     ['John Williams', 'London Symphony Orchestra']   \n",
      "987       925640         0          ['Ludwig van Beethoven', 'Rudolf Serkin']   \n",
      "921       970400         0  ['Ludwig van Beethoven', 'Wilhelm Furtwängler'...   \n",
      "872      1254022         0                              ['Abdel Halim Hafez']   \n",
      "949      1305307         0  ['Edward Elgar', 'Daniel Barenboim', 'London P...   \n",
      "\n",
      "                                            id_artists release_date  ...  \\\n",
      "670                         ['7p5EwRiUqxJxnOCcULTHex']   1992-03-23  ...   \n",
      "947  ['7y97mc3bZRFXzT2szRM4L4', '5k15M5itLxlNtLk7BG...         1941  ...   \n",
      "969  ['1JOQXgYdQV2yfrhewqx96o', '0KIwMoAf3M1ON2Du6P...         1942  ...   \n",
      "606  ['6aMD1KAa5i3Myy61cR8FiW', '7HjbJ8V87zrxkSzL1K...   1975-07-03  ...   \n",
      "946  ['5aIqB5nVVvmFsvSdExz408', '2sVr8Y8WfEQpWF4iwA...   1952-01-01  ...   \n",
      "..                                                 ...          ...  ...   \n",
      "845  ['3dRfiJ2650SZu6GbydcHNb', '5yxyJsFanEAuwSM5kO...   1977-01-01  ...   \n",
      "987  ['2wOqMjp9TyABvtHdOSOTUS', '0rmB1nZVDjwoCN3kQV...         1937  ...   \n",
      "921  ['2wOqMjp9TyABvtHdOSOTUS', '4tvRZdoY4H9Wgcf0w1...         1953  ...   \n",
      "872                         ['6IW026WCYU8L1WF79dfwss']   1952-12-31  ...   \n",
      "949  ['430byzy0c5bPn5opiu0SRd', '78sEozQOEJxzXegUuq...         1949  ...   \n",
      "\n",
      "     loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
      "670   -15.183     1       0.9470         0.416          0.000000    0.7640   \n",
      "947   -21.228     1       0.0490         0.992          0.830000    0.1120   \n",
      "969   -15.442     1       0.0764         0.941          0.055600    0.2640   \n",
      "606   -14.604     1       0.9080         0.794          0.000007    0.3810   \n",
      "946   -20.478     1       0.0410         0.980          0.000000    0.1100   \n",
      "..        ...   ...          ...           ...               ...       ...   \n",
      "845   -14.242     0       0.0360         0.820          0.836000    0.3600   \n",
      "987   -18.790     1       0.0543         0.994          0.922000    0.0864   \n",
      "921   -16.411     1       0.0369         0.968          0.908000    0.1020   \n",
      "872   -16.027     0       0.0405         0.989          0.861000    0.7420   \n",
      "949   -15.720     0       0.0355         0.932          0.798000    0.2540   \n",
      "\n",
      "     valence    tempo  time_signature  top50  \n",
      "670   0.7230   71.683               5      0  \n",
      "947   0.2170  125.377               3      0  \n",
      "969   0.1420   60.894               4      0  \n",
      "606   0.1100  105.859               3      0  \n",
      "946   0.3100  112.728               4      0  \n",
      "..       ...      ...             ...    ...  \n",
      "845   0.1100  136.715               4      0  \n",
      "987   0.0385   75.523               4      0  \n",
      "921   0.1110  129.634               4      0  \n",
      "872   0.1850  118.546               4      0  \n",
      "949   0.0472   77.604               4      0  \n",
      "\n",
      "[1050 rows x 23 columns]\n",
      "_________________________________________________________________________________\n",
      "     level_0   index                      id  \\\n",
      "685   400552  327971  7GoVgw7YIjblncehRC5sYj   \n",
      "405   251151  297832  0uXuwBSTOEoGAVzw5KbOwN   \n",
      "699   410688  365021  3Mu65I2pHk26cNosBnL7Nv   \n",
      "29        29   93813  2TksvaRivgAEj780DgRB73   \n",
      "400   255696  552344  4tmk3Yee7JVx5UIjQpOrbZ   \n",
      "..       ...     ...                     ...   \n",
      "143    91645  197210  462NxL8bZEDNKQV8fCQ1Ks   \n",
      "6          6   92813  0VjIjW4GlUZAMYd2vXMi3b   \n",
      "788   457232   21659  0Fa1EMoT3F5o47DXWTjpxN   \n",
      "365   230376  354338  4rrLIX4yCHpVglgnzxWibv   \n",
      "784   462758  421731  1HgS7AlIAUgWRB6i9sqEDt   \n",
      "\n",
      "                                                  name  popularity  \\\n",
      "685                                            หำเทียม          17   \n",
      "405                                             Xanadu          31   \n",
      "699                             Sen Sevgini Bana Sakla          16   \n",
      "29                                                 911          91   \n",
      "400                                                 証言          31   \n",
      "..                                                 ...         ...   \n",
      "143                       El Último Trago - Remastered          47   \n",
      "6                                      Blinding Lights          96   \n",
      "788  L'Oiseau de feu: Danse infernale de tous les s...          10   \n",
      "365                                      Love Too Good          33   \n",
      "784                                     Los Vergelitos          10   \n",
      "\n",
      "     duration_ms  explicit                                            artists  \\\n",
      "685       245533         0                        ['Carabao', 'Center Stage']   \n",
      "405       667293         0                                           ['Rush']   \n",
      "699       240093         0                                     ['Zeki Müren']   \n",
      "29        215891         1                                           ['Sech']   \n",
      "400       408360         0  ['LAMP EYE', 'RINO', 'YOU THE ROCK', 'G.K.MARY...   \n",
      "..           ...       ...                                                ...   \n",
      "143       153453         0                                 ['Chavela Vargas']   \n",
      "6         200040         0                                     ['The Weeknd']   \n",
      "788       280773         0  ['Igor Stravinsky', 'Columbia Symphony Orchest...   \n",
      "365       364893         0                             ['Jefferson Starship']   \n",
      "784       140640         0   ['Banda Sinaloense El Recodo De Cruz Lizarraga']   \n",
      "\n",
      "                                            id_artists release_date  ...  \\\n",
      "685  ['1LCwH85p61LDPxSg2uWUL9', '4cZ3QVotang675EbMa...   1987-01-23  ...   \n",
      "405                         ['2Hkut4rAAyrQxRdof7FVJq']   1977-09-01  ...   \n",
      "699                         ['0ZZDIo31D35xGrXYTodWrL']   1990-06-25  ...   \n",
      "29                          ['77ziqFxp5gaInVrF2lj4ht']   2021-02-05  ...   \n",
      "400  ['29xU3oMWZbFQasfpWUUPuC', '6XtRAMQzYANgrz2bgc...   1996-11-25  ...   \n",
      "..                                                 ...          ...  ...   \n",
      "143                         ['0WC6O2ZzUcDYvcmt2mGh8c']   1997-09-15  ...   \n",
      "6                           ['1Xyo4u8uXC1ZmMpatF05PJ']   2020-03-20  ...   \n",
      "788  ['7ie36YytMoKtPiL7tUvmoE', '1iNPygduJOu0Jnzaso...         1948  ...   \n",
      "365                         ['3HC7NcxQx2Yk0fWoRKJ0xF']   1978-02-06  ...   \n",
      "784                         ['7sDRPHDNEOmnPgyfYWUITM']   1963-09-11  ...   \n",
      "\n",
      "     loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
      "685    -6.219     1       0.0363       0.30900          0.000000    0.1670   \n",
      "405    -9.089     0       0.0506       0.13800          0.002080    0.0711   \n",
      "699   -16.415     1       0.0385       0.73900          0.000016    0.2560   \n",
      "29     -3.815     1       0.0422       0.07600          0.000002    0.2960   \n",
      "400    -8.278     0       0.2880       0.08180          0.000000    0.0940   \n",
      "..        ...   ...          ...           ...               ...       ...   \n",
      "143   -10.094     1       0.0551       0.97100          0.000099    0.1100   \n",
      "6      -5.934     1       0.0598       0.00146          0.000095    0.0897   \n",
      "788   -15.125     1       0.0536       0.91800          0.791000    0.1750   \n",
      "365   -14.198     0       0.0250       0.24100          0.148000    0.1200   \n",
      "784    -9.835     1       0.0391       0.57400          0.342000    0.8440   \n",
      "\n",
      "     valence    tempo  time_signature  top50  \n",
      "685   0.9640  131.027               4      0  \n",
      "405   0.0429  126.379               4      0  \n",
      "699   0.5820  126.563               4      0  \n",
      "29    0.7440   93.029               4      1  \n",
      "400   0.5900   98.961               4      0  \n",
      "..       ...      ...             ...    ...  \n",
      "143   0.5400  138.151               3      0  \n",
      "6     0.3340  171.005               4      1  \n",
      "788   0.2290   78.932               4      0  \n",
      "365   0.6920   91.875               4      0  \n",
      "784   0.9540  190.864               3      0  \n",
      "\n",
      "[1000 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chansons_data.iloc[50:,:]\n",
    "print(chansons_data)\n",
    "sample = chansons_data.sample(1000)\n",
    "print(\"_________________________________________________________________________________\")\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17]\n",
      " [ 0]\n",
      " [ 0]\n",
      " ...\n",
      " [ 1]\n",
      " [ 4]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "all_features_scaled = scaler.fit_transform(all_features)\n",
    "all_features_scaled\n",
    "print(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up an actual MLP model using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_dim=1),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    #model = Sequential()\n",
    "    #4 feature inputs going into an 6-unit layer (more does not seem to help - in fact you can go down to 4)\n",
    "    #model.add(Dense(6, input_dim=1, kernel_initializer='normal', activation='relu'))\n",
    "    # \"Deep learning\" turns out to be unnecessary - this additional hidden layer doesn't help either.\n",
    "     #model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    # Output layer with a binary classification (benign or malignant)\n",
    "     #model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model; rmsprop seemed to work best\n",
    "     #model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 220, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 154, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-19-e65f53a740af>\", line 6, in create_model\n",
      "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Wrap our Keras model in an estimator compatible with scikit_learn\n",
    "estimator = KerasClassifier(build_fn=create_model, nb_epoch=100, verbose=0)\n",
    "# Now we can use scikit_learn's cross_val_score to evaluate this model identically to the others\n",
    "cv_scores = cross_val_score(estimator, all_features_scaled,all_classes, cv=10)\n",
    "cv_scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "1/1 - 18s - loss: 0.8978 - mean_absolute_error: 0.1020 - mean_squared_error: 0.0516 - val_loss: 19.4694 - val_mean_absolute_error: 3.5865 - val_mean_squared_error: 19.4694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2934726b400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = create_model()\n",
    "model.fit(\n",
    "    all_features_scaled, # all_features_scaled,\n",
    "    all_classes,                        #all_classes,\n",
    "    batch_size=1200,\n",
    "    epochs= 1,\n",
    "    verbose=2,\n",
    "    class_weight={0: 1, 1: 20},\n",
    "    validation_data=(sample['popularity'], sample['top50'])\n",
    ")\n",
    "\n",
    "#chansons_data[['popularity']].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAccuracy(df,weight):\n",
    "    reussite = 0\n",
    "    size  = 0\n",
    "    for  itera,row in df.iterrows():  \n",
    "        print(row[0],end='')\n",
    "        print('/',end='')\n",
    "        print(row[1],end='')\n",
    "        if row[1]==1:\n",
    "            size += weight\n",
    "            if row[0]==row[1]:\n",
    "                reussite+= weight\n",
    "            else:\n",
    "                print(\"bad\")\n",
    "        else:\n",
    "            size += 1\n",
    "            if row[0]==row[1]:\n",
    "                reussite+= 1\n",
    "               \n",
    "        \n",
    "    return reussite/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simplon 1\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultat\n",
      "      prediction  realite\n",
      "0              1        0\n",
      "1              0        0\n",
      "2              0        0\n",
      "3              1        0\n",
      "4              0        0\n",
      "...          ...      ...\n",
      "1045           1        0\n",
      "1046           0        0\n",
      "1047           0        0\n",
      "1048           1        0\n",
      "1049           0        0\n",
      "\n",
      "[1050 rows x 2 columns]\n",
      "1/00/00/01/00/01/00/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/00/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/00/00/00/01/01/01/01/01/01/01/01/01/01/01/11/01/01/01/01/01/01/00/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/11/00/01/01/01/01/01/00/00/00/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/11/01/01/01/01/01/01/01/01/00/01/00/01/01/01/01/01/00/01/01/01/01/01/01/01/10/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/11/01/11/01/01/00/01/00/01/01/11/01/10/01/01/00/01/11/01/01/01/01/01/01/01/01/01/00/01/01/01/01/10/01/01/11/00/01/01/01/01/11/01/01/11/01/01/00/01/01/01/01/01/01/01/01/11/00/01/01/01/01/01/11/11/01/01/01/00/01/00/01/01/01/11/01/00/01/01/01/01/00/01/11/00/01/01/00/01/01/01/11/11/01/10/01/01/00/01/10/01/01/00/01/01/01/01/01/00/01/01/01/00/00/01/01/11/01/01/01/10/01/00/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/00/01/11/01/00/01/01/11/01/01/01/01/00/01/00/01/01/01/01/00/01/01/01/00/01/01/01/00/00/01/01/01/00/01/01/11/01/01/11/01/01/01/01/00/01/01/11/01/01/01/00/00/01/01/01/01/00/01/01/01/01/00/01/11/01/01/01/01/01/00/00/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/00/01/01/00/00/01/01/01/11/01/01/01/11/01/00/01/11/01/01/01/11/00/01/00/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/10/01/11/00/01/01/00/01/01/01/01/01/01/01/01/11/11/01/00/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/00/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/00/01/01/01/01/01/01/01/01/01/01/11/01/11/01/11/01/01/01/01/01/01/00/01/00/01/01/01/01/11/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/11/01/11/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/10/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/11/01/01/01/01/01/01/00/01/01/11/11/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/11/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/00/01/01/00/01/01/01/00/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/11/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/00/01/00/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/00/00/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/01/01/01/01/01/01/00/01/01/01/01/00/00/01/01/01/00/01/01/01/01/01/01/00/00/01/01/01/01/01/01/01/01/01/01/00/01/00/01/01/00/00/01/00/00.20363636363636364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exemple  =  chansons_data['popularity'].tail(1).to_numpy()\n",
    "\n",
    "column_names = ['prediction', 'realite']\n",
    "\n",
    "\n",
    "\n",
    "resultat = pd.DataFrame(columns = column_names,index=range(1050))\n",
    "\n",
    "resultat['realite'].append(sample['top50'])\n",
    "\n",
    "resultat['prediction']=pd.DataFrame(model.predict_classes(all_features))\n",
    "resultat['realite'] = all_classes\n",
    "print(\"resultat\")\n",
    "print(resultat)\n",
    "print(checkAccuracy(resultat,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## How did you do?\n",
    "\n",
    "Which topology, and which choice of hyperparameters, performed the best? Feel free to share your results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
